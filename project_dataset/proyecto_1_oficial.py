# -*- coding: utf-8 -*-
"""PROYECTO 1 - IRONHACK PAYMENTS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15SoNsQY4Ufes_8majAx2WGW-HWZhOHRR
"""
# ===============================================================================================================
#  1. Inportar librerías / bibliotecas de funciones.
# ===============================================================================================================

import os, sys, time
import platform
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from datetime import datetime
try:
    import msvcrt  # Solo en Windows
    _HAS_MSVCRT = True
except Exception:
    _HAS_MSVCRT = False


# --- PAUSAR Y CONTINUAR ---
def pausar():
    print()
    print("\n  Pulsa ESPACIO (o Enter) para continuar ...  \n")
    print()
    if _HAS_MSVCRT and sys.stdin is None:
        while True:
            if msvcrt.kbhit():
                ch = msvcrt.getch()
                if ch in (b' ', b'\r'):
                    print()
                    break
    else:
        try:
            input()
        except EOFError:
            time.sleep(1)


# --- BORRAR PANTALLA ---
def borrar_pantalla():

    if platform.system() == "Windows":
        os.system("cls")
    else:
        os.system("clear") 


borrar_pantalla()   

print("=============================================================")
print(" 1. IMPORTACIÓN DE LAS LIBRERÍAS O BIBLIOTECAS DE FUNCIONES. ")
print("=============================================================")
print()
print("Improtando librerías o bibliotecas de funciones ...")
print()

pausar()

# ===============================================================================================================
#  2. Cargar de los conjuntos de datos (datasets).
# ===============================================================================================================

print("==================================================================")
print(" 2. CARGA DE LOS CONJUNTOS DE DATOS (datasets) EN LOS DATAFRAMES. ")
print("==================================================================")
print()
print("Cargando los datasets en los data frames ...")
print()

pd.set_option('display.max_columns', None)
df_cash = pd.read_csv("extract - cash request - data analyst.csv")
df_fees = pd.read_csv("extract - fees - data analyst - .csv")
#df_lex = pd.read_excel("Lexique - Data Analyst.xlsx")

pausar()

# ===============================================================================================================
#  3. Análisis Exploratorio de Datos (EDA).
# ===============================================================================================================

print("==========================================")
print(" 3. ANÁLISIS EXPLORATORIO DE DATOS (EDA).")
print("==========================================")
print()
print("ANÁLISIS DE LOS DATA FRAMES")

## CASH Data frame

print("====================================")
print("------- INFORMACIÓN: df_cash -------")
print("====================================")    
print(df_cash.info())
print(df_cash.info())
print("-------------")
print(df_cash.shape)
print("-------------")
pausar()
print("====================================")
print("------------- Columnas -------------")
print("====================================")
print(df_cash.columns)
pausar()
print("====================================")
print("------------- Muestra --------------")
print("====================================")
print(df_cash.sample(10))
pausar()
pausar()
print("====================================")
print("------------- Cabecera -------------")
print("====================================")
print("\nPrimeras filas:")
print(df_cash.head(10).to_string(index=False))
pausar()
print("====================================")
print("--------------- Cola ---------------")
print("====================================")
print("\nültimas filas:")
print(df_cash.tail(10).to_string(index=False))
pausar()
print("====================================")
print("--------- Nulos por columna --------")
print("====================================")
print("\nNulos por columna:")
print(df_cash.isna().sum().sort_values(ascending=False).to_string())
pausar()
print("=======================================")
print("------------- Estadísticas ------------")
print("=======================================")
print("--- Variables estadísticas: df_cash ---")
print(df_cash.describe(include="all").transpose().to_string())
pausar()

"""## FEES Data frame"""

print("====================================")
print("------- INFORMACIÓN: df_fees -------")
print("====================================")    
print(df_fees.info())
print(df_fees.info())
print("-------------")
print(df_fees.shape)
print("-------------")
pausar()
print("====================================")
print("------------- Muestra --------------")
print("====================================")
print(df_fees.columns)
pausar()
print("====================================")
print("------------- Muestra --------------")
print("====================================")
print(df_fees.sample(10))
pausar()
pausar()
print("====================================")
print("------------- Cabecera -------------")
print("====================================")
print("\nPrimeras filas:")
print(df_fees.head(10).to_string(index=False))
pausar()
print("====================================")
print("--------------- Cola ---------------")
print("====================================")
print("\nültimas filas:")
print(df_fees.tail(10).to_string(index=False))
pausar()
print("====================================")
print("--------- Nulos por columna --------")
print("====================================")
print("\nNulos por columna:")
print(df_fees.isna().sum().sort_values(ascending=False).to_string())
pausar()
print("=======================================")
print("------------- Estadísticas ------------")
print("=======================================")
print("--- Variables estadísticas: df_fees ---")
print("=======================================")
print(df_fees.describe(include="all").transpose().to_string())
pausar()

## Análisis de valores NaN

# Análisis de NaN del Data Frame Cash

# Primero capturamos valores nulos
missing_values = pd.isnull(df_cash)

# Contamos cuantos NaN hay en cada columna
missing_values_column = missing_values.sum()
print("Cantidad de valores nulos POR COLUMNA:\n", missing_values_column)

pausar()

# Contamos cuantos NaN hay en total
total_missing_values = missing_values_column.sum()
print("Cantidad TOTAL de valores nulos:", total_missing_values)

pausar()

# Contamos cuantas columnas tienen valores NaN - FIJAR EL VALOR DE X depende del objetivo (X = 0 / 5 / 100 / ?)
columns_with_missing = missing_values_column[missing_values_column > 0].count()
print("Cantidad de columnas que tienen al menos 1 valor nulo:", columns_with_missing)

pausar()

# Análisis de NaN del Data Frame Fees

#Primero capturamos valores nulos
missing_values_f = pd.isnull(df_fees)

# Contamos cuantos NaN hay en cada columna
missing_values_column_f = missing_values_f.sum()
print("Cantidad de valores nulos POR COLUMNA:\n", missing_values_column_f)

pausar()

# Contamos cuantos NaN hay en total
total_missing_values_f = missing_values_column_f.sum()
print("Cantidad TOTAL de valores nulos:", total_missing_values_f)

pausar()

# Contamos cuantas columnas tienen valores NaN - FIJAR EL VALOR DE X depende del objetivo (X = 0 / 5 / 100 / ?)
columns_with_missing_f = missing_values_column_f[missing_values_column_f > 0].count()
print("Cantidad de columnas que tienen al menos 1 valor nulo:", columns_with_missing_f)

pausar


# ===============================================================================================================
#  4. LIMPIEZA Y MANIPULACIÓN DE DATOS.
# ===============================================================================================================

## Limpieza y manipulación de datos.

# Checkeamos que no existe un user_id con el valor 9999.
try:
   # 9999 in df_fees['user_id'].values
    user_id_9999_exists = 9999 in df_fees['user_id'].values
    if user_id_9999_exists:
        print("El user_id 9999 ya existe en df_fees. No se puede usar para rellenar NaN.")
    else:
        print("El user_id 9999 no existe en df_fees. Se puede usar para rellenar NaN.")
except Exception:
    # por si las rutas absolutas no existen, no interrumpimos flujo
    pass

pausar()

# Remplazar los valores NaN por user_id: 9999

df_cash['user_id'] = df_cash['user_id'].fillna(9999)

df_cash.nunique()

print(df_cash)

pausar()

# Convertimos las columnas de fecha al formato correcto

date_columns_cash = ['created_at', 'updated_at', 'moderated_at', 'reimbursement_date',
                     'cash_request_received_date', 'money_back_date', 'send_at',
                     'reco_creation', 'reco_last_update']  # Lista de columnas de fecha

for col in date_columns_cash:
    if col in df_cash.columns:
        df_cash[col] = pd.to_datetime(df_cash[col], errors='coerce')  # Convertir a datetime

pausar()

# Convertimos las columnas a formato Año-Mes

for col in date_columns_cash:
    if col in df_cash.columns:
        df_cash[col] = df_cash[col].dt.to_period('M')

print(df_cash)

pausar()    

# Convertimos las columnas de fecha al formato correcto

date_columns_fees = ['created_at', 'updated_at', 'paid_at', 'from_date', 'to_date']  # Lista de columnas de fecha

for col in date_columns_fees:
    if col in df_fees.columns:
        df_fees[col] = pd.to_datetime(df_fees[col], errors='coerce')  # Convertir a datetime

print(df_cash)

pausar()

# Convertimos las columnas a formato Año-Mes

for col in date_columns_fees:
    if col in df_fees.columns:
        df_fees[col] = df_fees[col].dt.to_period('M')

print(df_fees)

# ========================================================================================================================
#  4. MÉTRICAS PARA ANALZAR.
# ========================================================================================================================

print("=======================================")
print("------- Métricas de Cohortes. ---------")
print("=======================================")
print("--- Variables estadísticas: df_fees ---")
print("=======================================")

# --- MÉTRICAS DE COHORTES --- """# Gráficos"""

coss_status = pd.crosstab(df_cash['created_at'], df_cash['status'])

coss_status.plot(kind='bar', stacked=True)

"""# Merge de las Bases de datos"""

df_fees_with_cohort = df_fees.merge(
    df_cash[['id', 'user_id','amount','status', 'created_at', 'reimbursement_date', 'money_back_date', ]].drop_duplicates('id'),
    left_on='cash_request_id',
    right_on='id',
    how='left')
df_fees_with_cohort.sample(10)

pausar()  

# ========================================================================================================================
#  4.1. Métrica 1: Frecuencia de uso del servicio.
# ========================================================================================================================

# ¿Cuántos usuarios vuelven a usar el servicio cada mes (0,1,2...) desde que entraron?

"""# 1 - Frecuencia de uso del servicio"""

cohort_usage = (
    df_cash.groupby(['created_at'])
      .agg(
          total_anticipos=('id', 'count')
      )
      .reset_index()
)
cohort_usage

cohort_users = df_cash.groupby(['created_at'])['user_id'].nunique()

cohort_users

cohort_usage = (
    df_cash.groupby(['created_at'])
      .agg(
          usuarios_que_usaron=('user_id', 'nunique'),
          total_anticipos=('id', 'count')
      )
      .reset_index()
)
cohort_usage

# KPI 1 Frecuencia de uso del servicio
cohort_usage['Frecuencia_uso'] = cohort_usage['total_anticipos']/cohort_usage['usuarios_que_usaron']

print(cohort_usage)

pausar()

sns.barplot(data=cohort_usage, x="created_at", y="Frecuencia_uso", color="skyblue")
plt.xticks(rotation=45)
plt.title("Frecuencia de uso por grupo")
plt.ylabel("Frecuencia de uso")  # Establecemos la etiqueta del eje Y
plt.xlabel("Cohortes")  # Establecemos la etiqueta del eje Y
plt.show()

pausar()

"""# 2 - Tasa de incidencias"""

cohort_incidents = df_cash[~df_cash['recovery_status'].isna()]

print(cohort_incidents)

pausar()

table_incidents = cohort_incidents.groupby(['created_at'])['created_at'].count()

print(table_incidents)

pausar()

table_totals = df_cash.groupby(['created_at'])['created_at'].count()

print(table_totals)

pausar()

table_totals = table_totals.reset_index(name='total_count')

print(table_totals)

table_incidents = table_incidents.reset_index(name='incident_count')

print(table_incidents)

pausar()

table_merged = pd.merge(
    table_totals,
    table_incidents,
    on='created_at',
    how='left'
)

table_merged

table_merged['Incident_rate'] = round((table_merged['incident_count']/table_merged['total_count'])*100, 2)

print(table_merged)

pausar()

sns.barplot(data=table_merged, x="created_at", y="Incident_rate", color="orange")
plt.xticks(rotation=45)
plt.title("Variación de tasa de Incidentes")
plt.xlabel("Cohorte")
plt.ylabel("Tasa de incidencia")
plt.show()

pausar()

## Sacar únicamente los porcenajes de 2020
table_merged_2020 = table_merged[table_merged['created_at'].dt.year == 2020]

fig, axes = plt.subplots(3, 4, figsize=(12, 10))
axes = axes.flatten()

# Crear cada mini pie chart
for i, (idx, row) in enumerate(table_merged_2020.iterrows()):
    axes[i].pie(
        [row['Incident_rate'], 100 - row['Incident_rate']],
        autopct=lambda p: f"{row['Incident_rate']:.1f}%" if p > 0 and p < 50 else "",
        startangle=90,
        colors=['#2196F3', '#ABD9FF'],
        textprops={'fontsize': 9},
        wedgeprops={'edgecolor': 'white'},
    )
    axes[i].set_title(f"Cohorte {row['created_at']}", fontsize=10)

# Quitar el vacío
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

# Ajustes de espaciado
plt.suptitle("Promedio de incidentes por cohorte", fontsize=14, y=1.05)
plt.tight_layout()
plt.show()

pausar()

"""# 3 - Ganancias generadas por cohorte"""

# Punto 3: Ganancias por Cohorte
coho_mes = df_fees_with_cohort.groupby('created_at_x')['total_amount'].sum()
coho_mes

mes_users = df_fees_with_cohort.groupby('created_at_x')['user_id'].nunique()
mes_users

mes_users_ren = mes_users.rename({'total_amount':'total_amount_other'})
mes_users = pd.merge(coho_mes, mes_users, on='created_at_x', how='left', suffixes=('', '_other'))
mes_users

# PUNTO 3: KPI
# Ingresos generados por grupos
mes_users['LTV'] = mes_users['total_amount']/mes_users['user_id']
mes_users = mes_users.rename(columns={
    'created_at_x': 'cohort',
    'total_amount': 'Total amount per cohort',
    'user_id': 'Total users per cohort',
})
mes_users

mes_users.index.names = ['cohort']
mes_users

mes_users = mes_users.reset_index()

fig, ax1 = plt.subplots(figsize=(10, 6))

# --- Barras: Total amount per cohort ---
sns.barplot(
    x=mes_users.index,
    y='Total amount per cohort',
    data=mes_users,
    color='skyblue',
    alpha=0.7,
    ax=ax1
)
ax1.set_ylabel('Ingresos totales', color='steelblue')
ax1.tick_params(axis='y', labelcolor='steelblue')

# --- Línea: LTV (eje secundario) ---
ax2 = ax1.twinx()
sns.lineplot(
    x=mes_users.index,
    y='LTV',
    data=mes_users,
    color='crimson',
    marker='o',
    linewidth=2,
    ax=ax2
)
ax2.set_ylabel('LTV', color='crimson')
ax1.set_xlabel('Cohorte', color='blue')
ax2.tick_params(axis='y', labelcolor='crimson')

plt.title('Ingresos Totales vs LTV por cohorte')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# La gráfica nos dice que con el paso del tiempo hay más usuarios (total) pero que aportan menos (LTV)

sns.barplot(data=mes_users, x="cohort", y="LTV")

pausar()


"""# 4 - Nueva métrica: Velocidad de rembolso"""

df_nueva_metrica = pd.read_csv("extract - cash request - data analyst.csv")
# Convertimos las columnas de fecha al formato correcto

date_columns = ['created_at', 'updated_at', 'moderated_at', 'reimbursement_date',
                     'cash_request_received_date', 'money_back_date', 'send_at',
                     'reco_creation', 'reco_last_update']  # Lista de columnas de fecha

for col in date_columns:
    if col in df_nueva_metrica.columns:
        df_nueva_metrica[col] = pd.to_datetime(df_nueva_metrica[col], errors='coerce')  # Convertir a datetime


for col in date_columns:
    if col in df_nueva_metrica.columns:
        df_nueva_metrica[col] = df_nueva_metrica[col].dt.to_period('D')

df_nueva_metrica_clean = df_nueva_metrica.dropna(subset=['money_back_date', 'cash_request_received_date'])
df_nueva_metrica_clean

pausar

# ==========================================
#  Métrica 4 propuesta: Velocidad de repago
# ==========================================

# Interpretación: ¿Cuántos días tardan en devolver el dinero?
# payback_delay_days = money_back_date - cash_request_received_date

# Aseguramos que estas columnas sean datetime naive (ya las parseamos arriba)
if "money_back_date" in df_nueva_metrica_clean.columns and "cash_request_received_date" in df_nueva_metrica_clean.columns:
    # algunas filas pueden venir con NaT -> resta segura con dt.days
    payback_delay_days = (
        df_nueva_metrica_clean["money_back_date"] - df_nueva_metrica_clean["cash_request_received_date"]
    )
    df_nueva_metrica_clean["payback_delay_days"] = payback_delay_days
else:
    df_nueva_metrica_clean["payback_delay_days"] = np.nan

df_nueva_metrica_clean[['payback_delay_days', 'user_id']]

df_nueva_metrica_clean.sort_values(['payback_delay_days', 'user_id'], ascending=[False, True])

df_nueva_metrica_clean.to_csv('df_nueva_metrica_clean.csv', index=False) # Posterior análisis en Tableau

pausar()

borrar_pantalla()
